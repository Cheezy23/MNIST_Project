{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean Moylan\n",
    "<br>\n",
    "G00299424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "https://www.youtube.com/watch?v=wQ8BIBpya2k&t=1004s<br>\n",
    "https://nbviewer.jupyter.org/github/ianmcloughlin/jupyter-teaching-notebooks/blob/master/mnist.ipynb<br>\n",
    "https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started I downloaded the MNIST dataset from http://yann.lecun.com/exdb/mnist/\n",
    "<br>\n",
    "I first unziped the files into the /data directory to avoid using a library to extract from within this Notebook\n",
    "<br>\n",
    "The Nural network is going to be made up of the input layer, 2 hidden layers followed by an output layer using a sigmoid function to determine the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset consists of training and testing images that are 28 X 28 pixels<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](neuralnetwork.png \"Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# I found a useful way to import the dataset straight from tensorflow as follows\n",
    "mnistData = tf.keras.datasets.mnist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack, view and Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unpack the dataset, using this method of data retrieval we save on over complicating when reading it in\n",
    "# This will give us 4 sets of data in bytes. x_train, y_train, x_test and y_test\n",
    "(x_train, y_train), (x_test, y_test) = mnistData.load_data()\n",
    "\n",
    "# To display an image we can use matplot to help\n",
    "plt.imshow(x_train[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Train (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the data\n",
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Train', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "# summarize pixel values\n",
    "print('Train', x_train.min(), x_train.max(), x_train.mean(), x_train.std())\n",
    "print('Test', x_test.min(), x_test.max(), x_test.mean(), x_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for scaling pixel data between 0-1\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (60000, 28, 28))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e67d971fef7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prepare an iterators to scale images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batches train=%d, test=%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (60000, 28, 28))"
     ]
    }
   ],
   "source": [
    "# prepare an iterators to scale images\n",
    "train_iterator = datagen.flow(x_train, y_train, batch_size=64)\n",
    "test_iterator = datagen.flow(x_test, y_test, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can normalise the data\n",
    "\n",
    "#y_train = tf.keras.utils.normalize(y_train)\n",
    "#x_train = tf.keras.utils.normalize(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Layer is the input layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Rectified linear function is used as it is the default, can be changed later to test for better results\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# Outputlayer will have the same amount of nurons as there are numbers for output so 10\n",
    "# Softmax for probability distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model does not optimize accurecy but instead tries to minimise the loss\n",
    "\n",
    "# Adam optimizer with categorical crossentropy, \n",
    "#model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Same but with Stochastic gradient descent optimizer\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 528168561.9002 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 1518281956.4544 - accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 1135784296.0043 - accuracy: 0.0025\n",
      "Epoch 4/20\n",
      " 6368/60000 [==>...........................] - ETA: 3s - loss: 840542803.9397 - accuracy: 0.0151"
     ]
    }
   ],
   "source": [
    "# Here we set the Epochs = 10 which means we pass the training set through the network 10 times\n",
    "# This will give the model greater accuracy \n",
    "model.fit(x_train, y_train, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Stochastic gradient descent model (100% accuracy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.models.load_model('Adam MNIST model with 20 epochs (98.4% Accuracy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-501468535888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make a Prediction based on the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save model to json format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a Prediction based on the model\n",
    "predictions = my_model.predict([x_test])\n",
    "\n",
    "# save model to json format\n",
    "model_json = my_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[15])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
